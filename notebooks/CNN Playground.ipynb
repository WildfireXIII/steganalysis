{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Playground\n",
    "\n",
    "Following tutorial https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the fashion-mnist pre-shuffled train data and test data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
      "60000 train set\n",
      "10000 test set\n",
      "y = 2 Pullover\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f00501a7550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "\n",
    "# Define the text labels\n",
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Sneaker\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9\n",
    "\n",
    "# Image index, you can pick any number between 0 and 59,999\n",
    "img_index = 5\n",
    "# y_train contains the lables, ranging from 0 to 9\n",
    "label_index = y_train[img_index]\n",
    "# Print the label, for example 2 Pullover\n",
    "print (\"y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n",
    "# # Show one of the images from the training dataset\n",
    "plt.imshow(x_train[img_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n",
      "55000 train set\n",
      "5000 validation set\n",
      "10000 test set\n"
     ]
    }
   ],
   "source": [
    "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Print training set shape\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training, validation, and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_valid.shape[0], 'validation set')\n",
    "print(x_test.shape[0], 'test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               401664    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 412,778\n",
      "Trainable params: 412,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "54976/55000 [============================>.] - ETA: 0s - loss: 0.6003 - acc: 0.7792\n",
      "Epoch 00001: val_loss improved from inf to 0.39131, saving model to model.weights.best.hdf5\n",
      "55000/55000 [==============================] - 82s 1ms/step - loss: 0.6003 - acc: 0.7792 - val_loss: 0.3913 - val_acc: 0.8672\n",
      "Epoch 2/10\n",
      "54976/55000 [============================>.] - ETA: 0s - loss: 0.4089 - acc: 0.8507\n",
      "Epoch 00002: val_loss improved from 0.39131 to 0.31107, saving model to model.weights.best.hdf5\n",
      "55000/55000 [==============================] - 82s 1ms/step - loss: 0.4090 - acc: 0.8507 - val_loss: 0.3111 - val_acc: 0.8860\n",
      "Epoch 3/10\n",
      "54976/55000 [============================>.] - ETA: 0s - loss: 0.3640 - acc: 0.8673\n",
      "Epoch 00003: val_loss improved from 0.31107 to 0.29316, saving model to model.weights.best.hdf5\n",
      "55000/55000 [==============================] - 83s 2ms/step - loss: 0.3640 - acc: 0.8673 - val_loss: 0.2932 - val_acc: 0.8928\n",
      "Epoch 4/10\n",
      "54976/55000 [============================>.] - ETA: 0s - loss: 0.3384 - acc: 0.8757\n",
      "Epoch 00004: val_loss improved from 0.29316 to 0.27218, saving model to model.weights.best.hdf5\n",
      "55000/55000 [==============================] - 82s 1ms/step - loss: 0.3384 - acc: 0.8757 - val_loss: 0.2722 - val_acc: 0.9006\n",
      "Epoch 5/10\n",
      "54976/55000 [============================>.] - ETA: 0s - loss: 0.3204 - acc: 0.8827\n",
      "Epoch 00005: val_loss improved from 0.27218 to 0.27131, saving model to model.weights.best.hdf5\n",
      "55000/55000 [==============================] - 107s 2ms/step - loss: 0.3204 - acc: 0.8827 - val_loss: 0.2713 - val_acc: 0.9010\n",
      "Epoch 6/10\n",
      "54976/55000 [============================>.] - ETA: 0s - loss: 0.3057 - acc: 0.8878\n",
      "Epoch 00006: val_loss improved from 0.27131 to 0.25056, saving model to model.weights.best.hdf5\n",
      "55000/55000 [==============================] - 90s 2ms/step - loss: 0.3057 - acc: 0.8877 - val_loss: 0.2506 - val_acc: 0.9082\n",
      "Epoch 7/10\n",
      "54976/55000 [============================>.] - ETA: 0s - loss: 0.2933 - acc: 0.8924\n",
      "Epoch 00007: val_loss improved from 0.25056 to 0.23567, saving model to model.weights.best.hdf5\n",
      "55000/55000 [==============================] - 84s 2ms/step - loss: 0.2934 - acc: 0.8924 - val_loss: 0.2357 - val_acc: 0.9128\n",
      "Epoch 8/10\n",
      "54976/55000 [============================>.] - ETA: 0s - loss: 0.2833 - acc: 0.8941\n",
      "Epoch 00008: val_loss did not improve from 0.23567\n",
      "55000/55000 [==============================] - 84s 2ms/step - loss: 0.2833 - acc: 0.8941 - val_loss: 0.2466 - val_acc: 0.9076\n",
      "Epoch 9/10\n",
      "54976/55000 [============================>.] - ETA: 0s - loss: 0.2742 - acc: 0.8985\n",
      "Epoch 00009: val_loss improved from 0.23567 to 0.23462, saving model to model.weights.best.hdf5\n",
      "55000/55000 [==============================] - 82s 1ms/step - loss: 0.2743 - acc: 0.8984 - val_loss: 0.2346 - val_acc: 0.9126\n",
      "Epoch 10/10\n",
      "54976/55000 [============================>.] - ETA: 0s - loss: 0.2644 - acc: 0.9030\n",
      "Epoch 00010: val_loss improved from 0.23462 to 0.22607, saving model to model.weights.best.hdf5\n",
      "55000/55000 [==============================] - 82s 1ms/step - loss: 0.2644 - acc: 0.9030 - val_loss: 0.2261 - val_acc: 0.9168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f00a3e027f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights with the best validation accuracy\n",
    "model.load_weights('model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
